## RF-DETR Pretrained Weights

The RF-DETR model weights (~122 MB) are available as a GitHub Release asset. You can download them directly here:

[ğŸ”— rf_detr_803.pt (122 MB)](https://github.com/vkalinovski/-Basketball_foul_detection/releases/download/RF-DETR_WEIGHTS/rf_detr_803.pt)

# ğŸ“¡ **RF-DETR (ResNet-50 / ResNet-101 + Radar) â€” Video Object Detection & Tracking**

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1%2B-lightgrey.svg)
![Detectron2](https://img.shields.io/badge/Detectron2-0.6%2B-purple.svg)
![CUDA](https://img.shields.io/badge/CUDA-11.8-green.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.x-yellow.svg)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)
![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)

---

## ğŸ“– Overview  
**RF-DETR** (*Radar Frequency Detection Transformer*) is a hybrid CNN + Transformer architecture capable of:
- **Precisely localizing objects** across video frame sequences  
- **Maintaining tracking** even under noise, motion blur, and low resolution  
- **Integrating radar-frequency features** (range / Doppler) to augment visual perception  

All logic is implemented in **PyTorch 2.1** with **Detectron2 0.6**; the model can be easily extended with custom feature modules.

---

## ğŸ¯ TL;DR â€” Current Results  

| Metric (val)     | ResNet-50 | ResNet-101 |
|------------------|----------:|-----------:|
| **mAP @ 0.50**   | **0.427** | **0.451**  |
| mAP @ [0.50â€’0.95]| 0.273     | 0.288      |
| AR @ 100         | 0.381     | 0.396      |
| FPS (1080p, RTX 3090) | 29 fps | 24 fps   |

<sub>Training â€” 45 epochs, 2Ã—A100 80 GB, batch_size = 8, radar input: 20 channels.</sub>

---

## ğŸ“‚ Project Structure

    â”œâ”€â”€ rf-detr-train.ipynb        # Training pipeline
    â”œâ”€â”€ video_annotation.ipynb     # Video annotation & export
    â”œâ”€â”€ configs/
    â”‚   â”œâ”€â”€ default.yaml           # Base hyper-params
    â”‚   â””â”€â”€ radar_features.yaml    # RF-head settings
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/                   # Raw videos (.mp4 / .avi â€¦)
    â”‚   â””â”€â”€ labels/                # COCO annotations (.json)
    â”œâ”€â”€ outputs/
    â”‚   â”œâ”€â”€ checkpoints/           # Saved weights (.pth)
    â”‚   â””â”€â”€ annotated_videos/      # Result videos (.mp4)
    â””â”€â”€ README.md                  # Ğ­Ñ‚Ğ¾Ñ‚ Ñ„Ğ°Ğ¹Ğ»



---

## ğŸ“¦ Dataset  

| Source                          | Clips | Frames   | Size | Link         |
|---------------------------------|------:|---------:|-----:|--------------|
| **RF-Tracking Benchmark v1**    | 92    | 136,842  | 5.6 GB | _private S3_ |
| **YouTube (Creative Commons)**  | 51    | 78,014   | 3.4 GB | â€”            |
| **Total**                       | **143** | **214,856** | **9.0 GB** |  |

### Labeling  
- **Label Studio** with the **Video Object Tracking** plugin â†’ export COCO JSON  
- Radar data is synchronized by *timestamp* and stored as a second channel in HDF5 (`rf_range`, `rf_doppler`)  

---

## âš™ï¸ Notebook Breakdown  

| Block | Logic                                           | Notes                                             |
|-------|-------------------------------------------------|---------------------------------------------------|
| **B-1** | Mount Drive, check environment, âš™ï¸ `pip install -r requirements.txt` | Colab-friendly                                    |
| **B-2** | Parse RF + video, frame-batch selector        | 3-level cache (RAM â†’ NVMe â†’ S3)                    |
| **B-3** | `RFCOCODataset` + augmenter (Albumentations)  | RF channels are augmented synchronously            |
| **B-4** | Build RF-DETR (backbone, FPN, transformer heads) | Plug-and-play RF heads                            |
| **B-5** | Training loop: AdamW â†’ Cosine Annealing, AMP, EMA | Checkpoint on mAP improvements                    |
| **B-6** | Evaluation: mAP/mAR, confusion matrix, speed test | Tabular + graphical output                        |
| **B-7** | Export weights, TorchScript, ONNX              | Outputs saved in `outputs/checkpoints/`            |

---

## ğŸ§  Why This Model?  

| Component                 | Why                                                           |
|---------------------------|---------------------------------------------------------------|
| **DETR-style Transformer**| Learns global relationships â†” robust to occlusions             |
| **Radarâ€fusion head**     | RF channels â‰ˆ â€œsee through smoke/fogâ€ + depth information       |
| **FPN**                   | Handles objects of various sizes (drones â†” trucks)             |
| **AdamW + Cosine**        | Stable warmup, smooth LR decay                                 |
| **EMA**                   | Reduces noise from recent epochs â†’ improves mAP                |
| **AMP**                   | 1.7Ã— speedup, â€“45 % VRAM usage                                  |

---

## ğŸ› ï¸ Hyper-Parameters  

| Parameter           | Value       | Notes                    |
|---------------------|------------:|--------------------------|
| `EPOCHS`            | 45          | Full training run        |
| `BATCH_SIZE`        | 8           | 2Ã—A100 80 GB GPUs        |
| `LR_INIT`           | 1 eâˆ’4       | Base learning rate       |
| `LR_MIN`            | 1 eâˆ’6       | Cosine annealing floor   |
| `WEIGHT_DECAY`      | 5 eâˆ’4       |                           |
| `RF_CHANNELS`       | 20          | Range + Doppler channels |
| `EMA_DECAY`         | 0.9997      |                           |
| `IMG_SIZE`          | 960Ã—540     | Training resize          |
| `NUM_WORKERS`       | 8           |                           |
