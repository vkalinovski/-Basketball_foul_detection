{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmB28UPHSgi4",
    "outputId": "a70fa891-0236-42e5-e86b-c94fb8975347"
   },
   "source": [
    "# ===== 0. INSTALL =========================================\n",
    "!pip install -q pillow opencv-python moviepy tqdm supervision \\\n",
    "               torchaudio torchvision noisereduce \\\n",
    "               git+https://github.com/roboflow/rf-detr.git \\\n",
    "               accelerate openai\n",
    "\n",
    "print(\"Зависимости готовы (используем системный PyTorch).\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "tk_uopK0TMbx"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files, widgets\n",
    "import torch, cv2, moviepy.editor as mpy\n",
    "from tqdm.auto import tqdm\n",
    "from rfdetr import RFDETRBase\n",
    "from pathlib import Path\n",
    "import os, re, json, requests, base64, numpy as np, soundfile as sf, librosa\n",
    "import textwrap\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "WEIGHTS_PATH = '/content/drive/MyDrive/Colab Notebooks/rf_detr_803.pt'   # вес модели\n",
    "RESULT_DIR   = '/content/drive/MyDrive/Colab Notebooks/foul_results'     # куда класть вывод\n",
    "!mkdir -p \"$RESULT_DIR\"\n",
    "\n",
    "print(\"Пути настроены\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g51G773wS_7x",
    "outputId": "3960b550-4ce2-4460-bfc2-f781a43bcbc4"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "✅ Пути настроены\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "LOUxHGKyTZXd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = RFDETRBase(pretrain_weights=WEIGHTS_PATH, device=device_str)\n",
    "model.optimize_for_inference()\n",
    "print(\"✅  Модель загрузилась на\", device_str)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rj-qK_qgS_5s",
    "outputId": "bfdcf205-fddb-4ec7-d1f0-d61cbc21c1ed",
    "collapsed": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:rfdetr.main:num_classes mismatch: pretrain weights has 2 classes, but your model has 90 classes\n",
      "reinitializing detection head with 2 classes\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pretrain weights\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "\n",
      "WARNING:py.warnings:UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "\n",
      "WARNING:py.warnings:TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅  Модель загрузилась на cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "jfIx0oz5TcOc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files, widgets\n",
    "\n",
    "print(\"Выберите видео (.mp4)\")\n",
    "up = files.upload()\n",
    "assert len(up) == 1, \"Нужно загрузить 1 файл\"\n",
    "vid_name = next(iter(up))\n",
    "VID_PATH = f\"/content/{vid_name}\"\n",
    "print(\"✅ Видео на диске:\", VID_PATH)\n",
    "\n",
    "# VideoCapture / Writer\n",
    "cap  = cv2.VideoCapture(VID_PATH)\n",
    "fps  = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "W    = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H    = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "OUT_PATH = VID_PATH.replace(\".mp4\", \"_annotated.mp4\")\n",
    "writer   = cv2.VideoWriter(OUT_PATH, fourcc, fps, (W, H))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "ckX3iIVuS_32",
    "outputId": "db524622-7a8a-46e1-bb9a-f3e9f7e3e78d"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Выберите видео (.mp4)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7a944180-9439-4d19-b9da-5636c31bb434\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7a944180-9439-4d19-b9da-5636c31bb434\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving foull.mp4 to foull.mp4\n",
      "✅ Видео на диске: /content/foull.mp4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "iygIGgVDjcHr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "RESULT_DIR = \"/content/drive/MyDrive/Colab Notebooks/foul_results\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_PATH   = f\"{RESULT_DIR}/{Path(VID_PATH).stem}_annotated.mp4\"\n",
    "\n",
    "# папка для кадров\n",
    "FRAME_DIR  = f\"{RESULT_DIR}/frames\"\n",
    "os.makedirs(FRAME_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Результаты будут писаться в:\", RESULT_DIR)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAt77QG3jczW",
    "outputId": "c1d61bb6-348c-494d-d1fe-064013750b54"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅  Результаты будут писаться в: /content/drive/MyDrive/Colab Notebooks/foul_results\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "x4C3-jEaT5Di"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os, json, requests, base64, numpy as np, soundfile as sf, librosa\n",
    "\n",
    "DEEP_KEY   = \"9kScTQSpFJCd6OdxblR8bHjw3iWSPZkV\"\n",
    "WSPR_URL   = \"https://api.deepinfra.com/v1/inference/openai/whisper-large\"\n",
    "\n",
    "AUDIO_PATH = VID_PATH.replace(\".mp4\", \".wav\")\n",
    "!ffmpeg -loglevel error -y -i \"$VID_PATH\" -vn -ac 1 -ar 16000 \"$AUDIO_PATH\"\n",
    "\n",
    "audio_b64 = base64.b64encode(open(AUDIO_PATH, \"rb\").read()).decode()\n",
    "resp = requests.post(WSPR_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {DEEP_KEY}\"},\n",
    "        json={\"audio\": audio_b64, \"language\": \"en\", \"return_segments\": True},\n",
    "        timeout=300).json()\n",
    "\n",
    "with open(VID_PATH.replace(\".mp4\", \"_transcript.json\"), \"w\") as f:\n",
    "    json.dump(resp, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Whisper ok; пример:\", resp[\"segments\"][0][\"text\"][:60])\n",
    "\n",
    "# -----\n",
    "y, sr = sf.read(AUDIO_PATH, dtype=\"float32\")\n",
    "S     = np.abs(librosa.stft(y, n_fft=512, hop_length=256))**2\n",
    "freqs = librosa.fft_frequencies(sr=sr, n_fft=512)\n",
    "band  = (freqs > 2500) & (freqs < 4500)\n",
    "energy= S[band].mean(axis=0)\n",
    "thr   = energy.mean() + 3*energy.std()\n",
    "wh_secs = {int(i*256/sr) for i,e in enumerate(energy) if e > thr}\n",
    "\n",
    "print(f\"✅ Простых свистков найдено: {len(wh_secs)} секунд.\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zc-2uUQAS_1x",
    "outputId": "a6454ad7-b5b3-4586-f9e0-93fa51a2ed1a"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Whisper ok; пример:  It's two of three tonight.\n",
      "✅ Простых свистков найдено: 5 секунд.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "H2wkPFcyT7Po"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DEEPINFRA_API_KEY = \"9kScTQSpFJCd6OdxblR8bHjw3iWSPZkV\"\n",
    "CHAT_URL          = \"https://api.deepinfra.com/v1/openai/chat/completions\"\n",
    "MODEL_ID          = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "HEADERS_LLM = {\"Authorization\": f\"Bearer {DEEPINFRA_API_KEY}\",\n",
    "               \"Content-Type\": \"application/json\"}\n",
    "\n",
    "if \"trn\" not in globals():\n",
    "    with open(VID_PATH.replace(\".mp4\", \"_transcript.json\")) as f:\n",
    "        trn = json.load(f)\n",
    "segments = trn.get(\"segments\", [])\n",
    "wh_secs  = globals().get(\"wh_secs\", set())\n",
    "\n",
    "if not segments:\n",
    "    print(\"⚠️  Стенограмма пуста → calls = []\")\n",
    "    calls = []\n",
    "else:\n",
    "    WIN, STEP = 8.0, 4.0\n",
    "    windows, t = [], 0.0\n",
    "    total = segments[-1][\"end\"]\n",
    "    while t < total:\n",
    "        t_end = t + WIN\n",
    "        txt = \" \".join(s[\"text\"].strip()\n",
    "                       for s in segments\n",
    "                       if s[\"start\"] < t_end and s[\"end\"] > t)\n",
    "        windows.append((t, t_end, txt))\n",
    "        t += STEP\n",
    "\n",
    "\n",
    "    SYS_PROMPT = (\"You are an expert basketball referee analyst. \"\n",
    "                  \"Respond with ONE word only:\\n\"\n",
    "                  \"• foul\\n• no_foul\\n• other\")\n",
    "\n",
    "    def ask_llm(text_block: str) -> str:\n",
    "        payload = {\n",
    "            \"model\": MODEL_ID,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "                {\"role\": \"user\",   \"content\": text_block[:900]}\n",
    "            ],\n",
    "            \"temperature\": 0,\n",
    "            \"max_tokens\": 3\n",
    "        }\n",
    "        r = requests.post(CHAT_URL, json=payload, headers=HEADERS_LLM, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        word = re.split(r\"\\W+\", r.json()[\"choices\"][0][\"message\"][\"content\"].lower())[0]\n",
    "        return word if word in (\"foul\", \"no_foul\") else \"other\"\n",
    "\n",
    "\n",
    "    KW = re.compile(r\"\\b(foul|фол|play on|no foul)\\b\", re.I)\n",
    "    calls = []\n",
    "    for st, ed, txt in windows:\n",
    "        mid = int((st + ed) // 2)\n",
    "        if KW.search(txt) or mid in wh_secs:\n",
    "            lbl = ask_llm(txt)\n",
    "            if lbl != \"other\":\n",
    "                calls.append({\"start\": st, \"end\": ed, \"label\": lbl, \"text\": txt})\n",
    "\n",
    "    if not calls:\n",
    "        print(\"ℹ️  fallback: scanning first 90 s\")\n",
    "        for st, ed, txt in windows:\n",
    "            if st > 90: break\n",
    "            lbl = ask_llm(txt)\n",
    "            if lbl != \"other\":\n",
    "                calls.append({\"start\": st, \"end\": ed, \"label\": lbl, \"text\": txt})\n",
    "\n",
    "print(f\"✅ calls: {len(calls)}\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gv_cHxROS_z9",
    "outputId": "6306bc57-3960-4455-bb95-df610010d64c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ calls: 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "6jwgGuUUT9Vt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2, numpy as np, os\n",
    "from collections import defaultdict\n",
    "\n",
    "SCORE_TH = 0.4\n",
    "saved_secs = set()\n",
    "\n",
    "cap  = cv2.VideoCapture(VID_PATH)\n",
    "fps  = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "W, H = int(cap.get(3)), int(cap.get(4))\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    OUT_PATH,\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps, (W, H)\n",
    ")\n",
    "\n",
    "foul_secs = set()\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    rgb  = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    dets = model.predict(rgb, conf_thres=SCORE_TH)\n",
    "\n",
    "    sec_mark = int(frame_idx / fps)\n",
    "    foul_here = False\n",
    "\n",
    "    for box, conf, cls in zip(dets.xyxy, dets.confidence, dets.class_id):\n",
    "        if cls != 1:\n",
    "            continue\n",
    "        foul_here = True\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"foul {conf:.2f}\", (x1, y1 - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    if foul_here:\n",
    "        foul_secs.add(sec_mark)\n",
    "        if sec_mark not in saved_secs:\n",
    "            jpg_path = f\"{FRAME_DIR}/foul_{sec_mark:06d}.jpg\"\n",
    "            cv2.imwrite(jpg_path, frame)\n",
    "            saved_secs.add(sec_mark)\n",
    "\n",
    "    writer.write(frame)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release(); writer.release()\n",
    "print(f\"✅ Сохранены кадры: {len(saved_secs)} шт. → {FRAME_DIR}\")\n",
    "\n",
    "episodes = []\n",
    "if foul_secs:\n",
    "    cur_s = prev_s = min(foul_secs)\n",
    "    for s in sorted(foul_secs):\n",
    "        if s == prev_s or s == prev_s + 1:\n",
    "            prev_s = s\n",
    "        else:\n",
    "            episodes.append((cur_s, prev_s))\n",
    "            cur_s = prev_s = s\n",
    "    episodes.append((cur_s, prev_s))\n",
    "\n",
    "VOICE_END = globals().get(\"VOICE_END\",\n",
    "            (trn[\"segments\"][-1][\"end\"] if segments else 0))\n",
    "\n",
    "episodes_filt = [(s, e) for s, e in episodes if s <= VOICE_END + 3]\n",
    "print(\"✅ эпизодов после кластеризации:\", len(episodes_filt))\n"
   ],
   "metadata": {
    "id": "BdEW1YE4S_x3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "44d31742-9d5c-414d-a842-52054b311f1a"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Сохранены кадры: 7 шт. → /content/drive/MyDrive/Colab Notebooks/foul_results/frames\n",
      "✅ эпизодов после кластеризации: 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "78csTEKQUANk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd, numpy as np, textwrap\n",
    "\n",
    "def iou_time(a,b):\n",
    "    inter = max(0, min(a[1], b[1]) - max(a[0], b[0]))\n",
    "    union = max(a[1], b[1]) - min(a[0], b[0])\n",
    "    return inter / union if union else 0\n",
    "\n",
    "rows, used_calls, matches = [], set(), set()\n",
    "\n",
    "\n",
    "for i, (s, e) in enumerate(episodes_filt):\n",
    "\n",
    "    match_call = None\n",
    "    for j, c in enumerate(calls):\n",
    "        if j in used_calls: continue\n",
    "        if iou_time((s, e), (c[\"start\"], c[\"end\"])) > .3:\n",
    "            match_call = (j, c); used_calls.add(j); break\n",
    "\n",
    "    whistle = any(t in wh_secs for t in range(s, e+1))\n",
    "    match   = bool(match_call) or whistle\n",
    "    ref_lbl = (match_call[1][\"label\"] if match_call else\n",
    "               (\"whistle\" if whistle else \"—\"))\n",
    "    phrase  = match_call[1][\"text\"] if match_call else \"\"\n",
    "\n",
    "    rows.append(dict(ep_start=s, ep_end=e,\n",
    "                     model=\"foul\",\n",
    "                     referee=ref_lbl,\n",
    "                     phrase=phrase[:120],\n",
    "                     match=match))\n",
    "    if match: matches.add(i)\n",
    "\n",
    "\n",
    "for j,c in enumerate(calls):\n",
    "    if j not in used_calls and c[\"label\"]==\"foul\":\n",
    "        rows.append(dict(ep_start=int(c[\"start\"]),\n",
    "                         ep_end=int(c[\"end\"]),\n",
    "                         model=\"—\",\n",
    "                         referee=\"foul\",\n",
    "                         phrase=c[\"text\"][:120],\n",
    "                         match=False))\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"ep_start\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df.to_string(index=False))\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "\n",
    "tp = sum((r.match and r.model==\"foul\") for r in df.itertuples())\n",
    "fp = sum((r.model==\"foul\" and not r.match) for r in df.itertuples())\n",
    "fn = sum((r.referee in (\"foul\",\"whistle\") and not r.match) for r in df.itertuples())\n",
    "\n",
    "precision = tp / (tp + fp + 1e-9)\n",
    "recall    = tp / (tp + fn + 1e-9)\n",
    "f1        = 2*precision*recall/(precision+recall+1e-9)\n",
    "\n",
    "print(f\"\\nPrecision {precision:.2%}   Recall {recall:.2%}   F1 {f1:.2%}\")\n",
    "\n",
    "print(textwrap.dedent(f\"\"\"\n",
    "    ──────────────────────────────────────────────────────────────\n",
    "    **Что показывает таблица**\n",
    "\n",
    "    • ep_start / ep_end  – диапазон эпизода (секунды видео).\n",
    "    • model              – решение модели (здесь всегда 'foul').\n",
    "    • referee            – что слышно в аудио:\n",
    "        'foul'     – комментатор/рефери явно объявил фол;\n",
    "        'no_foul'  – наоборот, «без фола» / «play on»;\n",
    "        'whistle'  – слышен свисток, но слов нет;\n",
    "        '—'        – аудио ничего не сообщает.\n",
    "    • phrase             – сама фраза, если есть (обрезана 120 симв).\n",
    "    • match (True/False) – подтверждён ли эпизод аудио (фразой **или** свистком).\n",
    "\n",
    "    **Метрики**\n",
    "\n",
    "    Precision = TP / (TP + FP) — доля модельных эпизодов, подтверждённых аудио.\n",
    "    Recall    = TP / (TP + FN) — доля аудио-фолов, которые модель тоже нашла.\n",
    "    F1        — гармоническое среднее precision и recall.\n",
    "\n",
    "    Где TP — эпизоды, совпавшие c фразой 'foul' (IoU > 0.3) **или** содержащие свисток.\n",
    "    FP — “лишние” эпизоды модели, FN — фразы 'foul', без перекрывающего эпизода.\n",
    "    ──────────────────────────────────────────────────────────────\n",
    "\"\"\"))\n"
   ],
   "metadata": {
    "id": "mEnWiBlxS_vh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "56c32e50-b9bd-42a4-b01a-93ae0abb504c"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " ep_start  ep_end model referee                                                                                                                   phrase  match\n",
      "        1       7  foul    foul It's two of three tonight. They're not going away. Brooklyn will battle. Dennis Smith Jr. with a knockdown of Butler, an   True\n",
      "\n",
      "Precision 100.00%   Recall 100.00%   F1 100.00%\n",
      "\n",
      "──────────────────────────────────────────────────────────────\n",
      "**Что показывает таблица**\n",
      "\n",
      "• ep_start / ep_end  – диапазон эпизода (секунды видео).  \n",
      "• model              – решение модели (здесь всегда 'foul').  \n",
      "• referee            – что слышно в аудио:\n",
      "    'foul'     – комментатор/рефери явно объявил фол;\n",
      "    'no_foul'  – наоборот, «без фола» / «play on»;\n",
      "    'whistle'  – слышен свисток, но слов нет;\n",
      "    '—'        – аудио ничего не сообщает.\n",
      "• phrase             – сама фраза, если есть (обрезана 120 симв).  \n",
      "• match (True/False) – подтверждён ли эпизод аудио (фразой **или** свистком).\n",
      "\n",
      "**Метрики**\n",
      "\n",
      "Precision = TP / (TP + FP) — доля модельных эпизодов, подтверждённых аудио.  \n",
      "Recall    = TP / (TP + FN) — доля аудио-фолов, которые модель тоже нашла.  \n",
      "F1        — гармоническое среднее precision и recall.\n",
      "\n",
      "Где TP — эпизоды, совпавшие c фразой 'foul' (IoU > 0.3) **или** содержащие свисток.  \n",
      "FP — “лишние” эпизоды модели, FN — фразы 'foul', без перекрывающего эпизода.\n",
      "──────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {
    "id": "42YyAA8JUCI2"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "jB7pSm9_S_rL"
   },
   "execution_count": 10,
   "outputs": []
  }
 ]
}
